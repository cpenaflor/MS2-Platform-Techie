{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc5f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before normalization: ['date', 'users_active', 'total_sales', 'new_customers', 'report_generated', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50']\n",
      "Columns after normalization: ['date', 'users_active', 'total_sales', 'new_customers', 'report_generated', 'col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28', 'col_29', 'col_30', 'col_31', 'col_32', 'col_33', 'col_34', 'col_35', 'col_36', 'col_37', 'col_38', 'col_39', 'col_40', 'col_41', 'col_42', 'col_43', 'col_44', 'col_45', 'col_46', 'col_47', 'col_48', 'col_49', 'col_50']\n",
      "⚠️ No explicit ID column found; using date as identifier.\n",
      "Using id_col='date', date_col='date'\n",
      "▶️ Raw data shape: (100, 50)\n",
      "Missing % per column:\n",
      "col_10              40.0\n",
      "col_31              36.0\n",
      "col_37              34.0\n",
      "col_49              34.0\n",
      "col_50              34.0\n",
      "col_11              34.0\n",
      "col_16              33.0\n",
      "col_7               33.0\n",
      "col_14              33.0\n",
      "col_23              33.0\n",
      "col_13              32.0\n",
      "col_28              31.0\n",
      "col_19              31.0\n",
      "col_43              30.0\n",
      "col_8               29.0\n",
      "col_40              29.0\n",
      "col_22              28.0\n",
      "col_35              28.0\n",
      "col_25              27.0\n",
      "col_32              27.0\n",
      "col_44              27.0\n",
      "col_17              26.0\n",
      "col_46              26.0\n",
      "col_29              25.0\n",
      "col_38              25.0\n",
      "col_26              25.0\n",
      "col_34              24.0\n",
      "col_18              24.0\n",
      "col_20              24.0\n",
      "col_41              23.0\n",
      "col_47              23.0\n",
      "col_27              22.0\n",
      "col_36              20.0\n",
      "col_6               19.0\n",
      "col_42              19.0\n",
      "col_30              19.0\n",
      "col_12              19.0\n",
      "col_21              18.0\n",
      "col_24              18.0\n",
      "col_45              16.0\n",
      "col_15              16.0\n",
      "col_33              15.0\n",
      "col_39              14.0\n",
      "col_48              14.0\n",
      "col_9               13.0\n",
      "total_sales          0.0\n",
      "date                 0.0\n",
      "report_generated     0.0\n",
      "new_customers        0.0\n",
      "users_active         0.0\n",
      "dtype: float64\n",
      "After dropping cols, shape: (100, 5)\n",
      "Numeric columns to clean: ['users_active', 'total_sales', 'new_customers']\n",
      "Categorical columns to clean: ['report_generated']\n",
      "After date parsing & duplicate clean, shape: (100, 5)\n",
      "After numeric & category clean, shape: (100, 5)\n",
      "After outlier filtering, shape: (100, 5)\n",
      "✔️ Pandera validation passed\n",
      "✅ Cleaned data saved to: C:\\Users\\chang\\Desktop\\MS2 Platform Technology\\CLEANED_marketing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import Column, Check, DataFrameSchema\n",
    "\n",
    "#  File paths\n",
    "base_dir = r\"C:\\Users\\chang\\Desktop\\MS2 Platform Technology\"\n",
    "raw_path = os.path.join(base_dir, \"marketing_summary.csv\")\n",
    "clean_path = os.path.join(base_dir, \"CLEANED_marketing_summary.csv\")\n",
    "\n",
    "# 1 Load raw data & normalize column names\n",
    "df = pd.read_csv(raw_path)\n",
    "print(\"Columns before normalization:\", df.columns.tolist())\n",
    "# Standardize names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(r\"[ \\-]+\", \"_\", regex=True)\n",
    ")\n",
    "print(\"Columns after normalization:\", df.columns.tolist())\n",
    "\n",
    "# 2 Detect key columns\n",
    "def find_column(candidates, cols):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "id_col   = find_column([\"campaign_id\", \"id\", \"campaign\"], df.columns)\n",
    "date_col = find_column([\"campaign_date\", \"date\", \"report_date\"], df.columns)\n",
    "if id_col is None and date_col is not None:\n",
    "    print(\"⚠️ No explicit ID column found; using date as identifier.\")\n",
    "    id_col = date_col\n",
    "if date_col is None:\n",
    "    raise KeyError(f\"Date column missing. Available: {df.columns.tolist()}\")\n",
    "print(f\"Using id_col='{id_col}', date_col='{date_col}'\")\n",
    "\n",
    "# 3 Initial shape and missing-value overview\n",
    "print(f\"▶️ Raw data shape: {df.shape}\")\n",
    "print(\"Missing % per column:\")\n",
    "print((df.isnull().mean() * 100).sort_values(ascending=False))\n",
    "\n",
    "# 4 Drop high-null & irrelevant columns\n",
    "high_null = df.columns[df.isnull().mean() > 0.5]\n",
    "pattern_cols = [c for c in df.columns if c.startswith(\"col_\")]\n",
    "# Exclude essential\n",
    "drop_cols = [c for c in list(high_null) + pattern_cols if c not in [id_col, date_col]]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "print(f\"After dropping cols, shape: {df.shape}\")\n",
    "\n",
    "# Recompute numeric and categorical columns after drop\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = [c for c in df.select_dtypes(include=[\"object\"]).columns if c not in [id_col, date_col]]\n",
    "print(f\"Numeric columns to clean: {numeric_cols}\")\n",
    "print(f\"Categorical columns to clean: {cat_cols}\")\n",
    "\n",
    "# 5 Parse & clean key fields\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "df = df.dropna(subset=[date_col])  # ensure date exists\n",
    "df = df.drop_duplicates()\n",
    "print(f\"After date parsing & duplicate clean, shape: {df.shape}\")\n",
    "\n",
    "# 6 Numeric & categorical fixes\n",
    "# Numeric: cast to float and remove negatives\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(float)\n",
    "    df = df[df[col].ge(0)]\n",
    "# Categorical: strip, lower, cast to category\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str).str.strip().str.lower().astype(\"category\")\n",
    "print(f\"After numeric & category clean, shape: {df.shape}\")\n",
    "\n",
    "# 7 Outlier filtering on numeric metrics (1.5×IQR)\n",
    "for col in numeric_cols:\n",
    "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    df = df[df[col].between(lower, upper)]\n",
    "print(f\"After outlier filtering, shape: {df.shape}\")\n",
    "\n",
    "# 8 Define & apply Pandera schema\n",
    "schema_cols = {\n",
    "    id_col: Column(str, nullable=False),\n",
    "    date_col: Column(pa.DateTime, nullable=False)\n",
    "}\n",
    "for col in numeric_cols:\n",
    "    schema_cols[col] = Column(float, Check.ge(0), nullable=True)\n",
    "for col in cat_cols:\n",
    "    schema_cols[col] = Column(pa.Category, nullable=True)\n",
    "schema = DataFrameSchema(schema_cols)\n",
    "df = schema.validate(df, lazy=True)\n",
    "print(\"✔️ Pandera validation passed\")\n",
    "\n",
    "# 9 Save cleaned data\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(f\"✅ Cleaned data saved to: {clean_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880d1ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded marketing_summary with shape (100, 50)\n",
      "WARNING: Required columns missing: ['campaign_id', 'campaign_date']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== marketing_summary Pipeline Health Report ===\n",
      "Missing/Broken columns detected: ['campaign_id', 'campaign_date']\n",
      "Schema double check: Skipped\n",
      "Error Handling check: Passed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import Column, Check, DataFrameSchema\n",
    "\n",
    "# Setup minimal logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# File paths\n",
    "base_dir = r\"C:\\Users\\chang\\Desktop\\MS2 Platform Technology\"\n",
    "raw_path = os.path.join(base_dir, \"marketing_summary.csv\")\n",
    "\n",
    "# 1) Load data with error handling\n",
    "try:\n",
    "    df = pd.read_csv(raw_path)\n",
    "    logger.info(f\"Loaded marketing_summary with shape {df.shape}\")\n",
    "    error_handling = \"Passed\"\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load marketing_summary: {e}\")\n",
    "    df = pd.DataFrame()\n",
    "    error_handling = f\"Failed ({e})\"\n",
    "\n",
    "# Prepare health‐check report\n",
    "report = {\n",
    "    \"Missing/Broken columns detected\": None,\n",
    "    \"Schema double check\":             None,\n",
    "    \"Error Handling check\":            error_handling\n",
    "}\n",
    "\n",
    "# 2) Detect missing or broken columns\n",
    "required = [\"campaign_id\", \"campaign_date\"]\n",
    "missing  = [col for col in required if col not in df.columns]\n",
    "if missing:\n",
    "    report[\"Missing/Broken columns detected\"] = missing\n",
    "    logger.warning(f\"Required columns missing: {missing}\")\n",
    "else:\n",
    "    report[\"Missing/Broken columns detected\"] = []\n",
    "    logger.info(\"All required columns present\")\n",
    "\n",
    "# 3) Define Pandera schema for double-check\n",
    "schema = DataFrameSchema({\n",
    "    \"campaign_id\":   Column(str, nullable=False),\n",
    "    \"campaign_date\": Column(pa.DateTime, nullable=False),\n",
    "    **{\n",
    "        col: Column(float, Check.ge(0), nullable=True)\n",
    "        for col in df.select_dtypes(include=\"number\").columns\n",
    "    },\n",
    "})\n",
    "\n",
    "# 4) Run schema validation, capture outcome\n",
    "if not df.empty and not missing:\n",
    "    df[\"campaign_date\"] = pd.to_datetime(df[\"campaign_date\"], errors=\"coerce\")\n",
    "    try:\n",
    "        schema.validate(df, lazy=True)\n",
    "        report[\"Schema double check\"] = \"Passed\"\n",
    "        logger.info(\"Schema validation passed\")\n",
    "    except pa.errors.SchemaErrors as err:\n",
    "        report[\"Schema double check\"] = f\"Failed: {len(err.failure_cases)} errors\"\n",
    "        logger.error(\"Schema validation failed:\\n%s\", err.failure_cases)\n",
    "else:\n",
    "    report[\"Schema double check\"] = \"Skipped\"\n",
    "\n",
    "# 5) Print consolidated health report\n",
    "print(\"\\n=== marketing_summary Pipeline Health Report ===\")\n",
    "for k, v in report.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
